{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardboard = []\n",
    "for i in range(1,404):\n",
    "    temp = tf.keras.preprocessing.image.load_img(\n",
    "        path = \"trashnet/cardboard/cardboard\"+str(i)+\".jpg\",\n",
    "        grayscale=False, color_mode='rgb',target_size=(227,227))\n",
    "    X = np.array(temp)\n",
    "    cardboard.append(X)\n",
    "cardboard = np.array(cardboard)\n",
    "cardboard = np.take(cardboard,np.random.permutation(cardboard.shape[0]),axis=0)\n",
    "print(cardboard.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glass = []\n",
    "for i in range(1,502):\n",
    "    temp = tf.keras.preprocessing.image.load_img(\n",
    "        path = \"trashnet/glass/glass\"+str(i)+\".jpg\",\n",
    "        grayscale=False, color_mode='rgb',target_size=(227,227))\n",
    "    X = np.array(temp)\n",
    "    glass.append(X)\n",
    "glass = np.array(glass)\n",
    "glass = np.take(glass,np.random.permutation(glass.shape[0]),axis=0)\n",
    "print(glass.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metal = []\n",
    "for i in range(1,411):\n",
    "    temp = tf.keras.preprocessing.image.load_img(\n",
    "        path = \"trashnet/metal/metal\"+str(i)+\".jpg\",\n",
    "        grayscale=False, color_mode='rgb',target_size=(227,227))\n",
    "    X = np.array(temp)\n",
    "    metal.append(X)\n",
    "metal = np.array(metal)\n",
    "metal = np.take(metal,np.random.permutation(metal.shape[0]),axis=0)\n",
    "print(metal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = []\n",
    "for i in range(1,595):\n",
    "    temp = tf.keras.preprocessing.image.load_img(\n",
    "        path = \"trashnet/paper/paper\"+str(i)+\".jpg\",\n",
    "        grayscale=False, color_mode='rgb',target_size=(227,227))\n",
    "    X = np.array(temp)\n",
    "    paper.append(X)\n",
    "paper = np.array(paper)\n",
    "paper = np.take(paper,np.random.permutation(paper.shape[0]),axis=0)\n",
    "print(paper.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plastic = []\n",
    "for i in range(1,483):\n",
    "    temp = tf.keras.preprocessing.image.load_img(\n",
    "        path = \"trashnet/plastic/plastic\"+str(i)+\".jpg\",\n",
    "        grayscale=False, color_mode='rgb',target_size=(227,227))\n",
    "    X = np.array(temp)\n",
    "    plastic.append(X)\n",
    "plastic = np.array(plastic)\n",
    "plastic = np.take(plastic,np.random.permutation(plastic.shape[0]),axis=0)\n",
    "print(plastic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trash = []\n",
    "for i in range(1,138):\n",
    "    temp = tf.keras.preprocessing.image.load_img(\n",
    "        path = \"trashnet/trash/trash\"+str(i)+\".jpg\",\n",
    "        grayscale=False, color_mode='rgb',target_size=(227,227))\n",
    "    X = np.array(temp)\n",
    "    trash.append(X)\n",
    "trash = np.array(trash)\n",
    "trash = np.take(trash,np.random.permutation(trash.shape[0]),axis=0)\n",
    "print(trash.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.vstack((cardboard[:302,:,:,:],glass[:376,:,:,:],metal[:307,:,:,:],\n",
    "                    paper[:445,:,:,:],plastic[:361,:,:,:],trash[:103,:,:,:]))\n",
    "test_X = np.vstack((cardboard[302:,:,:,:],glass[376:,:,:,:],metal[307:,:,:,:],\n",
    "                   paper[445:,:,:,:],plastic[361:,:,:,:],trash[103:,:,:,:]))\n",
    "train_Y = np.zeros((6,train_X.shape[0]))\n",
    "test_Y = np.zeros((6,test_X.shape[0]))\n",
    "for i in range(train_X.shape[0]):\n",
    "    if(i<302):\n",
    "        train_Y[0][i] = 1\n",
    "    elif(i<678):\n",
    "        train_Y[1][i] = 1\n",
    "    elif(i<985):\n",
    "        train_Y[2][i] = 1\n",
    "    elif(i<1430):\n",
    "        train_Y[3][i] = 1\n",
    "    elif(i<1791):\n",
    "        train_Y[4][i] = 1\n",
    "    else:\n",
    "        train_Y[5][i] = 1\n",
    "for i in range(test_X.shape[0]):\n",
    "    if(i<101):\n",
    "        test_Y[0][i] = 1\n",
    "    elif(i<226):\n",
    "        test_Y[1][i] = 1\n",
    "    elif(i<329):\n",
    "        test_Y[2][i] = 1\n",
    "    elif(i<478):\n",
    "        test_Y[3][i] = 1\n",
    "    elif(i<599):\n",
    "        test_Y[4][i] = 1\n",
    "    else:\n",
    "        test_Y[5][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1013)\n",
    "train_perm = np.random.permutation(train_X.shape[0])\n",
    "train_X = np.take(train_X,train_perm,axis=0)\n",
    "print(train_X.shape)\n",
    "train_Y = np.take(train_Y,train_perm,axis=1)\n",
    "print(train_Y.shape)\n",
    "np.random.seed(901)\n",
    "test_perm = np.random.permutation(test_X.shape[0])\n",
    "test_X = np.take(test_X,test_perm,axis=0)\n",
    "print(test_X.shape)\n",
    "test_Y = np.take(test_Y,test_perm,axis=1)\n",
    "print(test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = tf.keras.layers.Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a')(X)\n",
    "    X = tf.keras.layers.BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = tf.keras.layers.Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b')(X)\n",
    "    X = tf.keras.layers.BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "    \n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = tf.keras.layers.Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c')(X)\n",
    "    X = tf.keras.layers.BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = tf.keras.layers.Add()([X_shortcut,X])\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = tf.keras.layers.Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a')(X)\n",
    "    X = tf.keras.layers.BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = tf.keras.layers.Conv2D(F2, (f, f), strides = (1,1), padding = 'same',name = conv_name_base + '2b')(X)\n",
    "    X = tf.keras.layers.BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = tf.keras.layers.Conv2D(F3, (1, 1), strides = (1,1), padding = 'valid',name = conv_name_base + '2c')(X)\n",
    "    X = tf.keras.layers.BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    ##### SHORTCUT PATH #### (≈2 lines)\n",
    "    X_shortcut = tf.keras.layers.Conv2D(F3, (1, 1), strides = (s,s), padding = 'valid',name = conv_name_base + '1')(X_shortcut)\n",
    "    X_shortcut = tf.keras.layers.BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = tf.keras.layers.Add()([X_shortcut,X])\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape = (227, 227, 3), classes = 6):\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = tf.keras.layers.Input(input_shape)\n",
    "\n",
    "    \n",
    "    # Zero-Padding\n",
    "    #X = tf.keras.layers.ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = tf.keras.layers.Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1')(X_input)\n",
    "    X = tf.keras.layers.BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "    X = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Stage 3 (≈4 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    # Stage 4 (≈6 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    # Stage 5 (≈3 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    X = tf.keras.layers.MaxPooling2D((2, 2))(X)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # output layer\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "    X = tf.keras.layers.Dense(classes, activation='softmax', name='fc' + str(classes))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = tf.keras.Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.000005), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_X, train_Y.T, epochs = 40, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.evaluate(test_X, test_Y.T)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
